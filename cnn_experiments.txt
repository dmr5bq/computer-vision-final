
------------------------ EXPERIMENT 1 ------------------------
model.add(Conv2D(32, kernel_size=(3, 3), activation='tanh',input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, kernel_size=(3, 3), activation='tanh'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(num_classes, activation='softmax'))

Epoch 1/10
150/150 [==============================] - 69s - loss: 1.1000 - acc: 0.3533     
Epoch 2/10
150/150 [==============================] - 69s - loss: 1.1038 - acc: 0.3800     
Epoch 3/10
150/150 [==============================] - 65s - loss: 1.1085 - acc: 0.3133     
Epoch 4/10
150/150 [==============================] - 62s - loss: 1.1363 - acc: 0.3267     
Epoch 5/10
150/150 [==============================] - 62s - loss: 1.1335 - acc: 0.3067     
Epoch 6/10
150/150 [==============================] - 64s - loss: 1.1233 - acc: 0.2600     
Epoch 7/10
150/150 [==============================] - 64s - loss: 1.0998 - acc: 0.3200     
Epoch 8/10
150/150 [==============================] - 63s - loss: 1.0991 - acc: 0.3800     
Epoch 9/10
150/150 [==============================] - 61s - loss: 1.0988 - acc: 0.4733     
Epoch 10/10
150/150 [==============================] - 60s - loss: 1.0975 - acc: 0.5467     
Training time: 643.820997953



------------------------ EXPERIMENT 2 ------------------------
model.add(Conv2D(32, kernel_size=(3, 3), activation='tanh',input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(num_classes, activation='softmax'))

Epoch 1/10
150/150 [==============================] - 62s - loss: 1.1000 - acc: 0.3333     
Epoch 2/10
150/150 [==============================] - 62s - loss: 1.1032 - acc: 0.2867     
Epoch 3/10
150/150 [==============================] - 63s - loss: 1.0986 - acc: 0.3067     
Epoch 4/10
150/150 [==============================] - 64s - loss: 1.0988 - acc: 0.3667     
Epoch 5/10
150/150 [==============================] - 62s - loss: 1.1032 - acc: 0.3200     
Epoch 6/10
150/150 [==============================] - 64s - loss: 1.0998 - acc: 0.3067     
Epoch 7/10
150/150 [==============================] - 62s - loss: 1.1005 - acc: 0.3267     
Epoch 8/10
150/150 [==============================] - 60s - loss: 1.0988 - acc: 0.3600     
Epoch 9/10
150/150 [==============================] - 61s - loss: 1.1003 - acc: 0.3467     
Epoch 10/10
150/150 [==============================] - 61s - loss: 1.0985 - acc: 0.3200     
Training time: 626.653222084




------------------------ EXPERIMENT 3 ------------------------
model.add(Conv2D(32, kernel_size=(3, 3), activation='tanh',input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, kernel_size=(3, 3), activation='tanh'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(num_classes, activation='softmax'))

Epoch 1/10
150/150 [==============================] - 69s - loss: 1.0961 - acc: 0.3533     
Epoch 2/10
150/150 [==============================] - 68s - loss: 1.1235 - acc: 0.3133     
Epoch 3/10
150/150 [==============================] - 64s - loss: 1.1184 - acc: 0.3267     
Epoch 4/10
150/150 [==============================] - 67s - loss: 1.1120 - acc: 0.2800     
Epoch 5/10
150/150 [==============================] - 67s - loss: 1.1089 - acc: 0.2933     
Epoch 6/10
150/150 [==============================] - 68s - loss: 1.0973 - acc: 0.3533     
Epoch 7/10
150/150 [==============================] - 75s - loss: 1.0999 - acc: 0.3333     
Epoch 8/10
150/150 [==============================] - 70s - loss: 1.1005 - acc: 0.3200     
Epoch 9/10
150/150 [==============================] - 72s - loss: 1.0993 - acc: 0.4200     
Epoch 10/10
150/150 [==============================] - 68s - loss: 1.0985 - acc: 0.3800     
Training time: 692.676518917




------------------------ EXPERIMENT 4 ------------------------
(EXPERIMENT 1 with Otsu thresholding during preprocessing)

Epoch 1/20
150/150 [==============================] - 76s - loss: 1.1016 - acc: 0.3800     
Epoch 2/10
150/150 [==============================] - 64s - loss: 1.0997 - acc: 0.3667     
Epoch 3/10
150/150 [==============================] - 61s - loss: 1.0989 - acc: 0.4600     
Epoch 4/10
150/150 [==============================] - 61s - loss: 1.0953 - acc: 0.7267     
Epoch 5/10
150/150 [==============================] - 65s - loss: 1.0943 - acc: 0.5267     
Epoch 6/10
150/150 [==============================] - 66s - loss: 1.0920 - acc: 0.4000     
Epoch 7/10
150/150 [==============================] - 64s - loss: 1.0892 - acc: 0.6933     
Epoch 8/10
150/150 [==============================] - 66s - loss: 1.0878 - acc: 0.6533     
Epoch 9/10
150/150 [==============================] - 70s - loss: 1.0793 - acc: 0.4333     
Epoch 10/10
150/150 [==============================] - 63s - loss: 1.0771 - acc: 0.5933     
Training time: 663.312577963

Epoch 1/10
150/150 [==============================] - 65s - loss: 1.1033 - acc: 0.3200     
Epoch 2/10
150/150 [==============================] - 62s - loss: 1.1098 - acc: 0.3067     
Epoch 3/10
150/150 [==============================] - 62s - loss: 1.0997 - acc: 0.2933     
Epoch 4/10
150/150 [==============================] - 61s - loss: 1.0979 - acc: 0.4533     
Epoch 5/10
150/150 [==============================] - 61s - loss: 1.1018 - acc: 0.4200     
Epoch 6/10
150/150 [==============================] - 61s - loss: 1.0915 - acc: 0.4000     
Epoch 7/10
150/150 [==============================] - 61s - loss: 1.0875 - acc: 0.7600     
Epoch 8/10
150/150 [==============================] - 60s - loss: 1.0844 - acc: 0.5667     
Epoch 9/10
150/150 [==============================] - 61s - loss: 1.0764 - acc: 0.9000     
Epoch 10/10
150/150 [==============================] - 62s - loss: 1.0655 - acc: 0.9933
**** saved in model-best *****

------------------------ EXPERIMENT 4 ------------------------
(with Otsu thresholding during preprocessing)
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(num_classes, activation='softmax'))


Epoch 1/10
150/150 [==============================] - 70s - loss: 1.0999 - acc: 0.3467     
Epoch 2/10
150/150 [==============================] - 65s - loss: 1.0993 - acc: 0.3267     
Epoch 3/10
150/150 [==============================] - 62s - loss: 1.1002 - acc: 0.3200     
Epoch 4/10
150/150 [==============================] - 65s - loss: 1.0998 - acc: 0.3200     
Epoch 5/10
150/150 [==============================] - 64s - loss: 1.0988 - acc: 0.3533     
Epoch 6/10
150/150 [==============================] - 64s - loss: 1.0991 - acc: 0.3867     
Epoch 7/10
150/150 [==============================] - 67s - loss: 1.0986 - acc: 0.4333     
Epoch 8/10
150/150 [==============================] - 67s - loss: 1.0980 - acc: 0.3667     
Epoch 9/10
150/150 [==============================] - 68s - loss: 1.0982 - acc: 0.3333     
Epoch 10/10
150/150 [==============================] - 66s - loss: 1.1020 - acc: 0.3200     
Training time: 665.114896059

